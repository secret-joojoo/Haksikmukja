# --- [ê¸´ê¸‰ íŒ¨ì¹˜] Python 3.13 í˜¸í™˜ì„± ë¬¸ì œ í•´ê²° (httpx êµ¬ë²„ì „ìš©) ---
import sys
if "cgi" not in sys.modules:
    import html
    from unittest.mock import MagicMock
    mock_cgi = MagicMock()
    def parse_header(line):
        parts = line.split(';')
        key = parts[0].strip()
        pdict = {}
        for part in parts[1:]:
            if '=' in part:
                name, value = part.split('=', 1)
                name = name.strip()
                value = value.strip().strip('"')
                pdict[name] = value
        return key, pdict
    mock_cgi.parse_header = parse_header
    mock_cgi.escape = html.escape
    sys.modules["cgi"] = mock_cgi
# -------------------------------------------------------------

from bs4 import BeautifulSoup
from datetime import date
from typing import List, Optional
import re
import httpx
from app.services.crawler.scrapers import BaseScraper
from app.schemas.crawler import SchoolData, CafeteriaData, MenuData

class KaistScraper(BaseScraper):
    # í¬ë¡¤ë§í•  ì‹ë‹¹ ëª©ë¡ ì •ì˜ (ì½”ë“œ: ì´ë¦„)
    CAFETERIAS = [
        {"code": "fclt", "name": "ì¹´ì´ë§ˆë£¨"},
        {"code": "west", "name": "ì„œë§›ê³¨"},
        {"code": "emp", "name": "êµìˆ˜íšŒê´€"},
    ]

    def __init__(self):
        super().__init__(
            school_name="KAIST",
            school_region="ëŒ€ì „",
            url="https://www.kaist.ac.kr/kr/html/campus/053001.html" 
        )

    async def fetch_html(self, cafeteria_code: str, target_date: date):
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }
        formatted_date = target_date.strftime("%Y-%m-%d")
        target_url = f"{self.url}?dvs_cd={cafeteria_code}&stt_dt={formatted_date}"
        
        print(f"  â³ ì ‘ì† ì‹œë„: {cafeteria_code} ({target_url})")

        # ğŸ”´ [ìˆ˜ì •] ì˜ˆì™¸ ì²˜ë¦¬ ê°•í™”: ì‚¬ì´íŠ¸ê°€ ì£½ì—ˆê±°ë‚˜ ì‘ë‹µì´ ì—†ìœ¼ë©´ ì¿¨í•˜ê²Œ ìŠ¤í‚µ!
        try:
            # timeout=10.0 ì¶”ê°€: 10ì´ˆ ë™ì•ˆ ì‘ë‹µ ì—†ìœ¼ë©´ ê·¸ëƒ¥ í¬ê¸°í•´ (ì„±ê²© ê¸‰í•´ì„œ ëª» ê¸°ë‹¤ë ¤)
            async with httpx.AsyncClient(verify=False, headers=headers, timeout=10.0) as client:
                response = await client.get(target_url)
                
                # ìƒíƒœ ì½”ë“œê°€ 200(ì„±ê³µ)ì¼ ë•Œë§Œ ë°ì´í„° ë°˜í™˜
                if response.status_code == 200:
                    response.encoding = "utf-8"
                    return response.text
                else:
                    # 404(ì—†ìŒ)ë‚˜ 500(ì„œë²„ ì—ëŸ¬) ê°™ì€ ê²Œ ëœ¨ë©´ ê²½ê³ ë§Œ ë‚¨ê¸°ê³  None ë°˜í™˜
                    print(f"     âš ï¸ ì ‘ì† ì‹¤íŒ¨ (Status: {response.status_code}) -> Skip")
                    return None

        except Exception as e:
            # ì¸í„°ë„· ì—°ê²°ì´ ì—†ê±°ë‚˜ íƒ€ì„ì•„ì›ƒ ë“± ëª¨ë“  ì—ëŸ¬ë¥¼ ì—¬ê¸°ì„œ ì¡ì•„ëƒ„
            print(f"     âŒ ì—ëŸ¬ ë°œìƒ: {cafeteria_code} ({str(e)}) -> Skip")
            return None

    def _clean_menu_item(self, text: str) -> str:
        """ë©”ë‰´ ì´ë¦„ ì •ë¦¬ ë° ì¡ë‹¤í•œ ê³µì§€ì‚¬í•­ ì œê±°"""
        # 1. ê´„í˜¸() ë˜ëŠ” ëŒ€ê´„í˜¸[] ì•ˆì— í¬í•¨ëœ ê°€ê²©/ì•Œë ˆë¥´ê¸° ì •ë³´ ì œê±°
        # ì˜ˆ: (1,5), [6,500ì›] -> ëª¨ë‘ ì œê±°
        text = re.sub(r'[\[\(][0-9.,ì›\s]+[\]\)]', '', text)
        
        # 3. [ì—…ë°ì´íŠ¸] ê³µì§€ì‚¬í•­ í‚¤ì›Œë“œ í•„í„°ë§ (ì—¬ê¸°ì— ë‹¨ì–´ ì¶”ê°€í•˜ë©´ ë‹¤ ì§€ì›Œì§!)
        ignore_keywords = [
            "ì²œì›", "ì œê³µ", "ìº í˜ì¸", "ìš´ì˜ì‹œê°„", "ì•ˆë…•í•˜ì„¸ìš”", 
            "í•™ìƒì¦", "ê°„ì‹", "ì°¸ê³ ", "ê°ì‚¬í•©ë‹ˆë‹¤", "ë¶€íƒ", "ì†Œì§€", "kcal"
        ]
        
        # ìœ„ ë‹¨ì–´ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜ (ì‚­ì œ)
        if any(keyword in text for keyword in ignore_keywords):
            return "" 
            
        return text

    def _clean_text_lines(self, element) -> List[str]:
        if not element: return []
        text = element.get_text(separator="\n")
        return [line.strip() for line in text.split("\n") if line.strip()]

    def _parse_breakfast_detailed(self, lines: List[str], target_date: date) -> List[MenuData]:
        menus = []
        current_category = "BREAKFAST" # ê¸°ë³¸ê°’: ì¼ë°˜ ì¡°ì‹
        current_items = []
        
        # ğŸ”´ [í•µì‹¬] ì¡°ì‹ í‚¤ì›Œë“œ ë¶„ë¦¬
        keywords = {
            "ì²œì›ì˜ ì•„ì¹¨ë°¥": "BREAKFAST_1000", # ì €ì¥ë  ì´ë¦„: BREAKFAST_1000
            "ì¡°ì‹": "BREAKFAST"          # ì €ì¥ë  ì´ë¦„: BREAKFAST (ê¸°ë³¸)
        }

        for line in lines:
            is_header = False
            for key, code in keywords.items():
                if key in line:
                    if current_items:
                        menus.append(MenuData(meal_type=current_category, menu_items=current_items, date=target_date))
                    
                    current_category = code
                    current_items = []
                    is_header = True
                    break
            
            if not is_header:
                # "ì¡°ì‹"ì´ë‚˜ "ì²œì›ì˜ ì•„ì¹¨ë°¥" ê°™ì€ í—¤ë” í…ìŠ¤íŠ¸ëŠ” ë©”ë‰´ì— í¬í•¨ë˜ë©´ ì•ˆ ë¨
                cleaned = self._clean_menu_item(line)
                if cleaned and len(cleaned) > 1 and "ì›" not in cleaned:
                    current_items.append(cleaned)

        if current_items:
            menus.append(MenuData(meal_type=current_category, menu_items=current_items, date=target_date))

        return menus


    def _parse_lunch_detailed(self, lines: List[str], target_date: date) -> List[MenuData]:
        menus = []
        current_category = "LUNCH" 
        current_items = []
        
        keywords = {
            "1ì¸µ ììœ¨ë°°ì‹": "LUNCH_1F",
            "2ì¸µ ììœ¨ë°°ì‹": "LUNCH_2F",
            "ììœ¨ë°°ì‹": "LUNCH",
            "Aì½”ë„ˆ": "LUNCH_A",
            "Bì½”ë„ˆ": "LUNCH_B",
            "ì¼í’ˆ": "LUNCH_SPECIAL",
            "êµì§ì›": "LUNCH_STAFF"
        }

        for line in lines:
            is_header = False
            for key, code in keywords.items():
                if key in line:
                    if current_items:
                        menus.append(MenuData(meal_type=current_category, menu_items=current_items, date=target_date))
                    current_category = code
                    current_items = []
                    is_header = True
                    break
            
            if not is_header:
                cleaned = self._clean_menu_item(line)
                # ê³µì§€ì‚¬í•­ í•„í„°ë§ í›„ ë‚´ìš©ì´ ë‚¨ì•˜ê³ , 'ì›' ê°™ì€ ê¸€ìê°€ ì—†ì–´ì•¼ ì¶”ê°€
                if cleaned and len(cleaned) > 1 and "ì›" not in cleaned:
                    current_items.append(cleaned)

        if current_items:
            menus.append(MenuData(meal_type=current_category, menu_items=current_items, date=target_date))

        return menus

    def _parse_dinner_detailed(self, lines: List[str], target_date: date) -> List[MenuData]:
        menus = []
        current_category = "DINNER" # ê¸°ë³¸ì€ ê·¸ëƒ¥ ì €ë…
        current_items = []
        
        # ğŸ”´ [ì¶”ê°€] ì €ë… íŠ¹ì‹ í‚¤ì›Œë“œ ì •ì˜
        keywords = {
            "ì¼í’ˆ": "ì„ì‹ ì¼í’ˆ",
        }

        for line in lines:
            is_header = False
            for key, code in keywords.items():
                if key in line:
                    # ìƒˆë¡œìš´ í‚¤ì›Œë“œê°€ ë‚˜ì˜¤ë©´ ì§€ê¸ˆê¹Œì§€ ëª¨ì€ ê±¸ ì €ì¥
                    if current_items:
                        menus.append(MenuData(meal_type=current_category, menu_items=current_items, date=target_date))
                    
                    current_category = code # ì¹´í…Œê³ ë¦¬ ë³€ê²½ (ì˜ˆ: DINNER -> DINNER_SPECIAL)
                    current_items = []
                    is_header = True
                    break
            
            if not is_header:
                if "ì„ì‹" in line: continue # "ì„ì‹" ê°™ì€ í—¤ë”ëŠ” ë¬´ì‹œ
                
                cleaned = self._clean_menu_item(line)
                # ë‚´ìš©ì´ ìˆê³  "ì›"ì´ í¬í•¨ë˜ì§€ ì•Šì€ ë©”ë‰´ë§Œ ì¶”ê°€
                if cleaned and len(cleaned) > 1 and "ì›" not in cleaned:
                    current_items.append(cleaned)

        # ë§ˆì§€ë§‰ì— ë‚¨ì€ ë©”ë‰´ë“¤ ì €ì¥
        if current_items:
            menus.append(MenuData(meal_type=current_category, menu_items=current_items, date=target_date))

        return menus

    async def parse(self, target_date: date) -> Optional[SchoolData]:
        print(f"âš¡ KAIST ì „ì²´ ì‹ë‹¹ íŒŒì‹± ì‹œì‘ ({target_date})")
        
        all_cafeterias = []

        for caf_info in self.CAFETERIAS:
            code = caf_info["code"]
            name = caf_info["name"]

            html = await self.fetch_html(code, target_date)
            if not html: continue
            
            soup = BeautifulSoup(html, 'html.parser')
            table = soup.find("table", class_="table")
            if not table: continue
            tbody = table.find("tbody")
            if not tbody: continue
            tr = tbody.find("tr")
            if not tr: continue
            tds = tr.find_all("td")
            if len(tds) < 3: continue

            daily_menus = []

            # [0] ì¡°ì‹
            bf_lines = self._clean_text_lines(tds[0])
            if bf_lines:
                # ì•„ê¹Œì˜ break ë¡œì§ì€ ë²„ë¦¬ê³ , ìƒì„¸ íŒŒì‹± í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•´!
                daily_menus.extend(self._parse_breakfast_detailed(bf_lines, target_date))

            # [1] ì¤‘ì‹ (ìƒì„¸ íŒŒì‹±)
            lunch_lines = self._clean_text_lines(tds[1])
            if lunch_lines:
                daily_menus.extend(self._parse_lunch_detailed(lunch_lines, target_date))

            # [2] ì„ì‹
            dn_lines = self._clean_text_lines(tds[2])
            if dn_lines:
                # ë‹¨ìˆœ íŒŒì‹± ëŒ€ì‹  ìƒì„¸ íŒŒì‹± í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•´ì„œ íŠ¹ì‹ì„ ë¶„ë¦¬í•´!
                daily_menus.extend(self._parse_dinner_detailed(dn_lines, target_date))

            if daily_menus:
                print(f"  âœ… {name} ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                all_cafeterias.append(CafeteriaData(name=name, menus=daily_menus))
            else:
                print(f"  âš ï¸ {name} ë°ì´í„° ì—†ìŒ")

        if not all_cafeterias:
            return None

        return SchoolData(
            school_name=self.school_name,
            school_region=self.school_region,
            cafeterias=all_cafeterias
        )