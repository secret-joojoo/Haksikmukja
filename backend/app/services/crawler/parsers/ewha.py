from bs4 import BeautifulSoup
from datetime import date
from typing import List, Optional
import httpx
import asyncio
from app.services.crawler.scrapers import BaseScraper
from app.schemas.crawler import SchoolData, CafeteriaData, MenuData

class EwhaScraper(BaseScraper):
    CAFETERIAS = [
        {"name": "I-House í•™ìƒì‹ë‹¹", "no": "339841"},
        {"name": "ì§„Â·ì„ Â·ë¯¸ê´€ ì‹ë‹¹", "no": "903"},
        {"name": "ê³µëŒ€ì‹ë‹¹", "no": "905"},
        {"name": "í•œìš°ë¦¬ì§‘ ì‹ë‹¹", "no": "899"},
        {"name": "E-House ì‹ë‹¹(201ë™)", "no": "900"},
    ]

    def __init__(self):
        super().__init__(
            school_name="ì´í™”ì—¬ìëŒ€í•™êµ",
            school_region="ì„œìš¸",
            url="https://www.ewha.ac.kr/ewha/life/restaurant.do"
        )

    async def fetch_html(self, article_no: str, target_date: date):
        # ğŸ’¡ ë‚ ì§œ íŒŒë¼ë¯¸í„°ë¥¼ srDtë¡œ ë„˜ê¸°ë”ë¼ë„ ì„œë²„ ì‘ë‹µì€ ì „ì²´ ì£¼ê°„ ë°ì´í„°ë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŒ
        formatted_date = target_date.strftime("%Y-%m-%d")
        target_url = (
            f"{self.url}?mode=view&articleNo={article_no}"
            f"&article.offset=0&articleLimit=10&srDt={formatted_date}"
        )
        
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Referer": "https://www.ewha.ac.kr/ewha/life/restaurant.do"
        }

        async with httpx.AsyncClient(verify=False, headers=headers, timeout=15.0) as client:
            try:
                response = await client.get(target_url)
                return response.text if response.status_code == 200 else None
            except Exception as e:
                print(f"âŒ [ì´í™”ì—¬ìëŒ€í•™êµ] ì ‘ì† ì—ëŸ¬: {e}")
                return None

    async def parse(self, target_date: date) -> Optional[SchoolData]:
        print(f"âš¡ [ì´í™”ì—¬ìëŒ€í•™êµ] {target_date} íŒŒì‹± ì‹œë„ ì¤‘...")
        all_cafeterias = []
        
        # ìš”ì¼ ì¸ë±ìŠ¤ ê³„ì‚° (0: ì›”, 1: í™”, ..., 6: ì¼)
        target_weekday = target_date.weekday()

        for caf in self.CAFETERIAS:
            html = await self.fetch_html(caf["no"], target_date)
            if not html: continue

            soup = BeautifulSoup(html, 'html.parser')
            menu_box = soup.select_one("ul.b-menu-box")
            if not menu_box: continue

            # ğŸ’¡ [í•µì‹¬ ìˆ˜ì •] ëª¨ë“  ìš”ì¼ ë¦¬ìŠ¤íŠ¸(li) ì¤‘ target_dateì— ë§ëŠ” ìš”ì¼ì„ ì„ íƒ
            # ì‚¬ì§„ì˜ í´ë˜ìŠ¤ëª… b-menu-day mon, tue ë“±ì„ í™œìš©í•˜ê±°ë‚˜ ë¦¬ìŠ¤íŠ¸ ìˆœì„œë¡œ ì ‘ê·¼
            day_lis = menu_box.select("li.b-menu-day")
            if not day_lis or target_weekday >= len(day_lis):
                continue

            target_li = day_lis[target_weekday]
            daily_menus = []

            # ì¡°ì‹, ì¤‘ì‹, ì„ì‹ div íƒìƒ‰
            meal_divs = target_li.select("div[class*='b-menu-']")

            for div in meal_divs:
                title_p = div.select_one("p.m-title")
                menu_pre = div.select_one("pre")
                
                if not title_p or not menu_pre: continue

                meal_type_raw = title_p.get_text(strip=True)
                if "ì¡°ì‹" in meal_type_raw: meal_type = "BREAKFAST"
                elif "ì¤‘ì‹" in meal_type_raw: meal_type = "LUNCH"
                elif "ì„ì‹" in meal_type_raw: meal_type = "DINNER"
                else: continue

                menu_text = menu_pre.get_text(strip=True)
                if not menu_text or "ë“±ë¡ëœ ì‹ë‹¨ì´ ì—†ìŠµë‹ˆë‹¤" in menu_text:
                    continue

                # ë©”ë‰´ ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸í™”
                menu_items = [item.strip() for item in menu_text.split() if item.strip()]
                
                if menu_items:
                    daily_menus.append(MenuData(
                        meal_type=meal_type,
                        menu_items=menu_items,
                        date=target_date
                    ))

            if daily_menus:
                print(f"  âœ… {caf['name']}: {len(daily_menus)}ê°œì˜ ì‹ë‹¨ ìˆ˜ì§‘ ì™„ë£Œ")
                all_cafeterias.append(CafeteriaData(name=caf["name"], menus=daily_menus))
            
            await asyncio.sleep(0.3) # ì„œë²„ ë¶€í•˜ ë°©ì§€

        if not all_cafeterias: return None

        return SchoolData(
            school_name=self.school_name,
            school_region=self.school_region,
            cafeterias=all_cafeterias
        )